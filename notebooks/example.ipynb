{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from vn1forecasting.dualt import (\n",
    "    DataPreprocessor, \n",
    "    generate_time_series_samples, prepare_batch_data, plot_predictions_vs_actual_with_price,\n",
    "    validate_model_with_loss, MultiTimeSeriesTransformer, run_inference_on_test, save_predictions_in_custom_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to MPS (Metal Performance Shaders) if available; otherwise, fallback to CPU\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessor()\n",
    "preprocessed_df = preprocessor.preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.head(196).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.loc[\n",
    "    (preprocessed_df.Client==0)&\n",
    "    (preprocessed_df.Warehouse==3)&\n",
    "    (preprocessed_df.Product==897)\n",
    "].set_index('Date').rolling_13w_sales.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.Price.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.Sales.hist(bins=100, range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.Sales.min(), preprocessed_df.Sales.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train and validation samples\n",
    "n_samples = 20  # Number of samples to generate\n",
    "train_samples, valid_samples = generate_time_series_samples(preprocessed_df, n_samples)\n",
    "train_samples[0]['sales'], train_samples[0]['price'], train_samples[0]['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = prepare_batch_data(train_samples, mode='train')\n",
    "sales, price, decoder_input, wom, woy, moy, qoy, sales_padding_mask, price_padding_mask, price_validity_mask, target, client, warehouse, product, rolling_4w_sales, rolling_13w_sales = batch_data\n",
    "price_padding_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "model = MultiTimeSeriesTransformer(\n",
    "    input_dim=1,\n",
    "    d_model=64,\n",
    "    nhead=4,\n",
    "    num_encoder_layers=2,\n",
    "    num_decoder_layers=2,\n",
    "    dim_feedforward=256,\n",
    "    num_wom=5,\n",
    "    num_woy=53,\n",
    "    num_moy=12,\n",
    "    num_qoy=4,\n",
    "    date_embedding_dim=3,\n",
    "    num_clients=len(preprocessor.client_encoder.classes_),\n",
    "    num_warehouses=len(preprocessor.warehouse_encoder.classes_),\n",
    "    num_products=len(preprocessor.product_encoder.classes_),\n",
    "    category_embedding_dim=16,\n",
    "    dropout=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_module_by_name(model, module_name_substring):\n",
    "    \"\"\"\n",
    "    Freeze all parameters whose name contains 'module_name_substring'.\n",
    "    i.e., param.requires_grad = False\n",
    "    \"\"\"\n",
    "    for name, param in model.named_parameters():\n",
    "        if module_name_substring in name:\n",
    "            param.requires_grad = False\n",
    "\n",
    "def unfreeze_module_by_name(model, module_name_substring):\n",
    "    \"\"\"\n",
    "    Unfreeze all parameters whose name contains 'module_name_substring'.\n",
    "    i.e., param.requires_grad = True\n",
    "    \"\"\"\n",
    "    for name, param in model.named_parameters():\n",
    "        if module_name_substring in name:\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phase, n_epochs, batch_size, n_samples, lr in [\n",
    "    ('init', 1, 24, 50000, 1e-3),\n",
    "    ('core', 51, 512, 200000, 1e-3),\n",
    "    ('core', 51, 512, 1, 1e-4),\n",
    "    ('core', 51, 512, 1, 1e-5),\n",
    "    ('tune', 51, 512, 200000, 1e-5),\n",
    "    ('finish', 51, 512, 200000, 1e-5)\n",
    "]:\n",
    "    loss_fn = nn.MSELoss(reduction='none')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "    # 1) Phase-Specific Freezing\n",
    "    # ---------------------------------------------------------------------------\n",
    "    if phase == 'tune':\n",
    "        # Freeze all embeddings: \n",
    "        freeze_module_by_name(model, 'embedding')\n",
    "        freeze_module_by_name(model, 'sales_encoder')\n",
    "        print(\"Froze all embedding layers.\")\n",
    "        print(\"Froze the sales encoder.\")\n",
    "\n",
    "    if phase == 'finish':\n",
    "        # Freeze the price encoder:\n",
    "        freeze_module_by_name(model, 'price_encoder')\n",
    "        unfreeze_module_by_name(model, 'sales_encoder')\n",
    "        print(\"Froze the price encoder.\")\n",
    "        print(\"Unfroze the sales encoder.\")\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "    # 2) Sample Generation\n",
    "    # ---------------------------------------------------------------------------\n",
    "    if phase in ['init', 'tune', 'finish']:\n",
    "        train_samples, valid_samples = [], []\n",
    "    _train_samples, _valid_samples = generate_time_series_samples(\n",
    "        preprocessed_df, n_samples, train_valid_split=0.8, phase=phase\n",
    "    )\n",
    "    train_samples += _train_samples\n",
    "    valid_samples += _valid_samples\n",
    "    print(f\"Training samples: {len(train_samples)}\")\n",
    "\n",
    "    # Initialize early stopping variables\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # ---------------------------------------------------------------------------\n",
    "    # 3) Train/Eval Loop for this Phase\n",
    "    # ---------------------------------------------------------------------------\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        # Shuffle train samples\n",
    "        np.random.shuffle(train_samples)\n",
    "\n",
    "        # Process training batches\n",
    "        for i in range(0, len(train_samples), batch_size):\n",
    "            # Prepare batch data\n",
    "            batch_samples = train_samples[i:i + batch_size]\n",
    "            batch_data = prepare_batch_data(batch_samples, mode='train', device=device)\n",
    "            (sales, price, decoder_input, wom, woy, moy, qoy,\n",
    "             sales_padding_mask, price_padding_mask, price_validity_mask,\n",
    "             client, warehouse, product, target, rolling_4w_sales,\n",
    "             rolling_13w_sales) = batch_data\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(\n",
    "                sales, price, decoder_input, wom, woy, moy, qoy,\n",
    "                sales_padding_mask, price_padding_mask, price_validity_mask,\n",
    "                client, warehouse, product, rolling_4w_sales, rolling_13w_sales\n",
    "            ).squeeze(-1)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = model.masked_loss(predictions, target)\n",
    "\n",
    "            # Backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_predictions, val_targets = validate_model_with_loss(\n",
    "            model, valid_samples, batch_size=batch_size, device=device\n",
    "        )\n",
    "        print(f\"Epoch {epoch}, Train Loss: {total_train_loss / (len(train_samples) // batch_size):.4f}, \"\n",
    "              f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Additional metrics (MSE, MAE)\n",
    "        valid_mask = ~np.isnan(val_targets)\n",
    "        val_mse = np.mean((val_predictions[valid_mask] - val_targets[valid_mask]) ** 2)\n",
    "        val_mae = np.mean(np.abs(val_predictions[valid_mask] - val_targets[valid_mask]))\n",
    "        print(f\"Validation MSE: {val_mse:.4f}\")\n",
    "        print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch} epochs - no val loss improvement for {patience} epochs\")\n",
    "            model.load_state_dict(best_model_state)\n",
    "            break\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Current learning rate: {current_lr:.2e}\")\n",
    "\n",
    "    # Ensure best model for next phase\n",
    "    model.load_state_dict(best_model_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessed_df.loc[preprocessed_df.Product==1293]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample from validation data\n",
    "sample_index = 7\n",
    "sample = valid_samples[sample_index]  # Replace 0 with the desired index\n",
    "\n",
    "# Plot predictions vs actuals\n",
    "plot_predictions_vs_actual_with_price(\n",
    "    sample=sample,\n",
    "    scalers=preprocessor.normalization_params,  # Access the normalization scalers\n",
    "    preprocessor=preprocessor,  # Pass the preprocessor for inverse_transform\n",
    "    val_predictions=val_predictions[sample_index],  # Optional, if not already in sample\n",
    "    val_targets=val_targets[sample_index]  # Optional, if not already in sample\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test samples\n",
    "test_samples = generate_time_series_samples(\n",
    "    preprocessed_df,\n",
    "    mode='test'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "test_predictions = run_inference_on_test(\n",
    "    model=model,\n",
    "    test_samples=test_samples,\n",
    "    batch_size=128,\n",
    "    preprocessor=preprocessor,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./test_predictions_custom.csv\"\n",
    "\n",
    "# Save predictions in custom format\n",
    "formatted_df = save_predictions_in_custom_format(\n",
    "    test_predictions=test_predictions, \n",
    "    test_samples=test_samples, \n",
    "    output_path=output_path\n",
    ")\n",
    "\n",
    "# Preview the formatted DataFrame\n",
    "print(formatted_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_df.senoni.min(), formatted_df.senoni.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def read_and_prepare_data(file_path: str, value_name: str = \"y\") -> pd.DataFrame:\n",
    "    \"\"\"Reads data in wide format and converts it to long format with `unique_id`, `ds`, and `y` columns.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df[\"unique_id\"] = df[[\"Client\", \"Warehouse\", \"Product\"]].astype(str).agg(\"-\".join, axis=1)\n",
    "    df = df.drop([\"Client\", \"Warehouse\", \"Product\"], axis=1)\n",
    "    df = df.melt(id_vars=[\"unique_id\"], var_name=\"ds\", value_name=value_name)\n",
    "    df[\"ds\"] = pd.to_datetime(df[\"ds\"])\n",
    "    return df.sort_values(by=[\"unique_id\", \"ds\"])\n",
    "\n",
    "def get_competition_forecasts() -> pd.DataFrame:\n",
    "    \"\"\"Reads competition forecasts and merges them into a single DataFrame.\"\"\"\n",
    "    places = [\"1st\", \"2nd\", \"3rd\", \"4th\", \"5th\"]\n",
    "    fcst_dfs = [read_and_prepare_data(f\"../data/solution_{place}_place.csv\", place) for place in places]\n",
    "    return pd.concat(fcst_dfs, axis=1).loc[:, ~pd.concat(fcst_dfs, axis=1).columns.duplicated()]\n",
    "\n",
    "# Prepare data\n",
    "fcst_df_comp = get_competition_forecasts()\n",
    "res = formatted_df.iloc[:, :3].merge(fcst_df_comp, on=[\"unique_id\", \"ds\"], how=\"left\")\n",
    "actual = read_and_prepare_data(\"../data/phase_2_sales.csv\")\n",
    "result = actual[[\"unique_id\", \"ds\", \"y\"]].merge(res, on=[\"unique_id\", \"ds\"], how=\"left\")\n",
    "\n",
    "# Verify unique_id consistency\n",
    "assert set(res[\"unique_id\"].unique()) == set(result[\"unique_id\"].unique()), \"Some unique_ids are missing\"\n",
    "\n",
    "# Compute scores\n",
    "scores = {\n",
    "    model: round(\n",
    "        (\n",
    "            np.nansum(np.abs(result[model] - result[\"y\"])) + \n",
    "            np.abs(np.nansum(result[model] - result[\"y\"]))\n",
    "        ) / result[\"y\"].sum(),\n",
    "        4\n",
    "    )\n",
    "    for model in res.columns if model not in [\"unique_id\", \"ds\"]\n",
    "}\n",
    "\n",
    "# Create and sort score DataFrame\n",
    "score_df = pd.DataFrame(scores.items(), columns=[\"model\", \"score\"]).sort_values(by=\"score\").reset_index(drop=True)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
