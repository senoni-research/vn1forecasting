{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from vn1forecasting.data import DataPreprocessor, generate_time_series_samples, prepare_batch_data\n",
    "from vn1forecasting.model import MultiTimeSeriesTransformer\n",
    "from vn1forecasting.pipeline import train_model, validate_model_with_loss, run_inference_on_test\n",
    "from vn1forecasting.results import save_predictions_in_custom_format, evaluate_forecasts\n",
    "from vn1forecasting.utils import plot_predictions_vs_actual_with_price\n",
    "\n",
    "# Set the device to MPS (Metal Performance Shaders) if available; otherwise, fallback to CPU\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessor()\n",
    "preprocessed_df = preprocessor.preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.loc[\n",
    "    (preprocessed_df.Client==0)&\n",
    "    (preprocessed_df.Warehouse==3)&\n",
    "    (preprocessed_df.Product==897)\n",
    "].set_index('Date').rolling_13w_sales.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.Price.hist(bins=100, range=(0.1, 0.8999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.Sales.hist(bins=100, range=(0.1001,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train and validation samples\n",
    "n_samples = 20  # Number of samples to generate\n",
    "train_samples, valid_samples = generate_time_series_samples(preprocessed_df, n_samples)\n",
    "train_samples[0]['cursor_date'], train_samples[0]['sales'], train_samples[0]['price'], train_samples[0]['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = prepare_batch_data(train_samples, mode='train')\n",
    "sales, price, decoder_input, wom, woy, moy, qoy, sales_padding_mask, price_padding_mask, price_validity_mask, target, client, warehouse, product, rolling_4w_sales, rolling_13w_sales = batch_data\n",
    "price_padding_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "model = MultiTimeSeriesTransformer(\n",
    "    input_dim=1,\n",
    "    d_model=64,\n",
    "    nhead=4,\n",
    "    num_encoder_layers=2,\n",
    "    num_decoder_layers=2,\n",
    "    dim_feedforward=256,\n",
    "    num_wom=5,\n",
    "    num_woy=53,\n",
    "    num_moy=12,\n",
    "    num_qoy=4,\n",
    "    date_embedding_dim=3,\n",
    "    num_clients=len(preprocessor.client_encoder.classes_),\n",
    "    num_warehouses=len(preprocessor.warehouse_encoder.classes_),\n",
    "    num_products=len(preprocessor.product_encoder.classes_),\n",
    "    category_embedding_dim=16,\n",
    "    dropout=0.1\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model, valid_samples, val_predictions, val_targets = train_model(\n",
    "    model=model,\n",
    "    preprocessed_df=preprocessed_df,\n",
    "    device=device,\n",
    "    generate_time_series_samples=generate_time_series_samples,\n",
    "    prepare_batch_data=prepare_batch_data,\n",
    "    validate_model_with_loss=validate_model_with_loss,\n",
    "    phases_config=[\n",
    "        ('init', 1, 24, 50000, 1e-3),\n",
    "        ('core', 51, 512, 200000, 1e-3),\n",
    "        ('core', 51, 512, 1, 1e-4),\n",
    "        ('core', 51, 512, 1, 1e-5),\n",
    "        ('tune', 51, 512, 200000, 1e-5),\n",
    "        ('finish', 51, 512, 200000, 1e-5)\n",
    "    ],\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample from validation data\n",
    "sample_index = 7\n",
    "sample = valid_samples[sample_index]  # Replace 0 with the desired index\n",
    "\n",
    "# Plot predictions vs actuals\n",
    "plot_predictions_vs_actual_with_price(\n",
    "    sample=sample,\n",
    "    scalers=preprocessor.normalization_params,  # Access the normalization scalers\n",
    "    preprocessor=preprocessor,  # Pass the preprocessor for inverse_transform\n",
    "    val_predictions=val_predictions[sample_index],  # Optional, if not already in sample\n",
    "    val_targets=val_targets[sample_index]  # Optional, if not already in sample\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test samples\n",
    "test_samples = generate_time_series_samples(\n",
    "    preprocessed_df,\n",
    "    mode='test'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "test_predictions = run_inference_on_test(\n",
    "    model=model,\n",
    "    test_samples=test_samples,\n",
    "    batch_size=512,\n",
    "    prepare_batch_data=prepare_batch_data,\n",
    "    preprocessor=preprocessor,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./test_predictions_custom.csv\"\n",
    "\n",
    "# Save predictions in custom format\n",
    "formatted_df = save_predictions_in_custom_format(\n",
    "    test_predictions=test_predictions, \n",
    "    test_samples=test_samples, \n",
    "    output_path=output_path\n",
    ")\n",
    "\n",
    "# Preview the formatted DataFrame\n",
    "print(formatted_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_paths = [\n",
    "    (\"../data/solution_1st_place.csv\", \"1st\"),\n",
    "    (\"../data/solution_2nd_place.csv\", \"2nd\"),\n",
    "    (\"../data/solution_3rd_place.csv\", \"3rd\"),\n",
    "    (\"../data/solution_4th_place.csv\", \"4th\"),\n",
    "    (\"../data/solution_5th_place.csv\", \"5th\"),\n",
    "]\n",
    "\n",
    "# Evaluate forecasts\n",
    "actual_path = \"../data/phase_2_sales.csv\"\n",
    "score_df = evaluate_forecasts(actual_path, formatted_df, forecast_paths)\n",
    "print(\"Model Scores:\")\n",
    "print(score_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
